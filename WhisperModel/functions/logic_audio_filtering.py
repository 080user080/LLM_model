# functions/logic_audio_filtering.py
"""GPU-–ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–∞ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –∞—É–¥—ñ–æ –¥–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è"""
import numpy as np
import torch
import scipy.signal as signal
from colorama import Fore

class AudioFilter:
    """–°–∏—Å—Ç–µ–º–∞ —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—ó –∞—É–¥—ñ–æ –∑ GPU-–ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é"""
    
    def __init__(self, sample_rate=16000):
        self.sample_rate = sample_rate
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤
        self.deepfilter = None
        self.vad_model = None
        self.silero_utils = None
        
        self._init_deepfilter()
        self._init_vad()
        
        print(f"{Fore.GREEN}‚úÖ AudioFilter —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ –Ω–∞ {self.device}")
    
    def _init_deepfilter(self):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è GPU —à—É–º–æ–¥–∞–≤—É (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ DeepFilterNet)"""
        try:
            # –°–ø—Ä–æ–±–∞ 1: noisereduce –∑ GPU
            import noisereduce as nr
            self.noisereduce = nr
            print(f"{Fore.GREEN}‚úÖ NoiseReduce –≥–æ—Ç–æ–≤–∏–π")
        except ImportError:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  NoiseReduce –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é Spectral Gating")
            self.noisereduce = None
    
    def _init_vad(self):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è Silero VAD"""
        try:
            model, utils = torch.hub.load(
                repo_or_dir='snakers4/silero-vad',
                model='silero_vad',
                force_reload=False,
                onnx=False
            )
            
            self.vad_model = model.to(self.device)
            self.silero_utils = utils
            print(f"{Fore.GREEN}‚úÖ Silero VAD –≥–æ—Ç–æ–≤–∏–π")
        except Exception as e:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  Silero VAD –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π: {e}")
    
    def apply_bandpass_filter(self, audio):
        """–ß–∞—Å—Ç–æ—Ç–Ω–∏–π –∫–æ—Ä–∏–¥–æ—Ä: 100 Hz - 7500 Hz"""
        try:
            nyquist = self.sample_rate / 2
            low = 100 / nyquist
            high = 7500 / nyquist
            
            # Butterworth —Ñ—ñ–ª—å—Ç—Ä 4-–≥–æ –ø–æ—Ä—è–¥–∫—É
            b, a = signal.butter(4, [low, high], btype='band')
            filtered = signal.filtfilt(b, a, audio)
            
            return filtered.astype(np.float32)
        except Exception as e:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  Bandpass –ø–æ–º–∏–ª–∫–∞: {e}")
            return audio
    
    def apply_compression(self, audio, threshold_db=-20, ratio=3.0, makeup_db=4):
        """–ö–æ–º–ø—Ä–µ—Å—ñ—è –¥–ª—è —Å—Ç–∞–±—ñ–ª—ñ–∑–∞—Ü—ñ—ó –≥—É—á–Ω–æ—Å—Ç—ñ"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è dB —É –ª—ñ–Ω—ñ–π–Ω–∏–π –º–∞—Å—à—Ç–∞–±
            threshold = 10 ** (threshold_db / 20)
            makeup = 10 ** (makeup_db / 20)
            
            # –û–±—á–∏—Å–ª–µ–Ω–Ω—è envelope
            abs_audio = np.abs(audio)
            
            # –ö–æ–º–ø—Ä–µ—Å—ñ—è
            compressed = np.where(
                abs_audio > threshold,
                threshold + (abs_audio - threshold) / ratio,
                abs_audio
            )
            
            # –í—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è –∑–Ω–∞–∫—É
            compressed = np.sign(audio) * compressed
            
            # Makeup gain
            compressed *= makeup
            
            # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
            max_val = np.max(np.abs(compressed))
            if max_val > 0:
                compressed = compressed / max_val * 0.95
            
            return compressed.astype(np.float32)
        except Exception as e:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  –ö–æ–º–ø—Ä–µ—Å—ñ—è –ø–æ–º–∏–ª–∫–∞: {e}")
            return audio
    
    def adaptive_wiener_filter(self, audio):
        """–ê–¥–∞–ø—Ç–∏–≤–Ω–∏–π Wiener —Ñ—ñ–ª—å—Ç—Ä –¥–ª—è —à—É–º—É (GPU)"""
        try:
            audio_tensor = torch.from_numpy(audio).to(self.device)
            
            # STFT
            n_fft = 512
            hop_length = 160
            
            stft = torch.stft(
                audio_tensor,
                n_fft=n_fft,
                hop_length=hop_length,
                return_complex=True
            )
            
            magnitude = torch.abs(stft)
            phase = torch.angle(stft)
            
            # –û—Ü—ñ–Ω–∫–∞ SNR –¥–ª—è –∫–æ–∂–Ω–æ—ó —á–∞—Å—Ç–æ—Ç–∏
            noise_est = torch.median(magnitude, dim=1, keepdim=True)[0]
            
            # Wiener gain
            snr = (magnitude ** 2) / (noise_est ** 2 + 1e-8)
            wiener_gain = snr / (snr + 1)
            
            # –ó–∞—Å—Ç–æ—Å—É–≤–∞—Ç–∏ —Ñ—ñ–ª—å—Ç—Ä
            filtered_mag = magnitude * wiener_gain
            filtered_stft = filtered_mag * torch.exp(1j * phase)
            
            # Inverse STFT
            audio_filtered = torch.istft(
                filtered_stft,
                n_fft=n_fft,
                hop_length=hop_length,
                length=len(audio_tensor)
            )
            
            result = audio_filtered.cpu().numpy()
            print(f"{Fore.CYAN}üéõÔ∏è  Wiener —Ñ—ñ–ª—å—Ç—Ä –∑–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–æ (GPU)")
            return result.astype(np.float32)
            
        except Exception as e:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  Wiener –ø–æ–º–∏–ª–∫–∞: {e}")
            return audio
    
    def remove_silence_vad(self, audio):
        """–í–∏–¥–∞–ª–µ–Ω–Ω—è —Ç–∏—à—ñ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é Silero VAD"""
        if self.vad_model is None or self.silero_utils is None:
            return audio
        
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –≤ torch tensor
            audio_tensor = torch.from_numpy(audio).to(self.device)
            
            # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –º—ñ—Ç–∫–∏ –º–æ–≤–ª–µ–Ω–Ω—è
            speech_timestamps = self.silero_utils[0](
                audio_tensor,
                self.vad_model,
                sampling_rate=self.sample_rate
            )
            
            if not speech_timestamps:
                print(f"{Fore.YELLOW}‚ö†Ô∏è  VAD: –º–æ–≤–ª–µ–Ω–Ω—è –Ω–µ –≤–∏—è–≤–ª–µ–Ω–æ")
                return audio
            
            # –í–∏—Ä—ñ–∑–∞—Ç–∏ —Ç—ñ–ª—å–∫–∏ —á–∞—Å—Ç–∏–Ω–∏ –∑ –º–æ–≤–ª–µ–Ω–Ω—è–º
            speech_parts = []
            for timestamp in speech_timestamps:
                start = timestamp['start']
                end = timestamp['end']
                speech_parts.append(audio[start:end])
            
            if speech_parts:
                result = np.concatenate(speech_parts)
                print(f"{Fore.CYAN}‚úÇÔ∏è  VAD: {len(audio)} ‚Üí {len(result)} —Å–µ–º–ø–ª—ñ–≤")
                return result
            
            return audio
            
        except Exception as e:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  VAD –ø–æ–º–∏–ª–∫–∞: {e}")
            return audio
    
    def spectral_gate_denoise(self, audio):
        """–°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω–µ —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–Ω—è (GPU-–ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–µ —á–µ—Ä–µ–∑ torch)"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç—É–≤–∞—Ç–∏ –≤ torch –¥–ª—è GPU –æ–±—á–∏—Å–ª–µ–Ω—å
            audio_tensor = torch.from_numpy(audio).to(self.device)
            
            # STFT (Short-Time Fourier Transform)
            n_fft = 512
            hop_length = 160
            
            # –û–±—á–∏—Å–ª–µ–Ω–Ω—è STFT –Ω–∞ GPU
            stft = torch.stft(
                audio_tensor,
                n_fft=n_fft,
                hop_length=hop_length,
                return_complex=True
            )
            
            # Magnitude —Ç–∞ Phase
            magnitude = torch.abs(stft)
            phase = torch.angle(stft)
            
            # –û—Ü—ñ–Ω–∫–∞ —à—É–º–æ–≤–æ–≥–æ –ø—Ä–æ—Ñ—ñ–ª—é (–ø–µ—Ä—à—ñ 0.5 —Å–µ–∫—É–Ω–¥–∏)
            noise_frames = int(0.5 * self.sample_rate / hop_length)
            noise_profile = torch.mean(magnitude[:, :noise_frames], dim=1, keepdim=True)
            
            # Spectral Gating (–º'—è–∫–µ –ø—Ä–∏–¥—É—à–µ–Ω–Ω—è)
            noise_threshold = 2.0  # –ê–≥—Ä–µ—Å–∏–≤–Ω—ñ—Å—Ç—å (1.5-3.0)
            mask = magnitude / (noise_profile + 1e-8)
            mask = torch.clamp(mask / noise_threshold, 0, 1)
            
            # –ó–∞—Å—Ç–æ—Å—É–≤–∞—Ç–∏ –º–∞—Å–∫—É
            filtered_magnitude = magnitude * mask
            
            # –í—ñ–¥–Ω–æ–≤–∏—Ç–∏ —Å–∏–≥–Ω–∞–ª
            filtered_stft = filtered_magnitude * torch.exp(1j * phase)
            
            # Inverse STFT
            audio_filtered = torch.istft(
                filtered_stft,
                n_fft=n_fft,
                hop_length=hop_length,
                length=len(audio_tensor)
            )
            
            result = audio_filtered.cpu().numpy()
            print(f"{Fore.CYAN}üéõÔ∏è  Spectral Gate –∑–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–æ (GPU)")
            return result.astype(np.float32)
            
        except Exception as e:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  Spectral Gate –ø–æ–º–∏–ª–∫–∞: {e}")
            return audio
    
    def deepfilter_denoise(self, audio):
        """–®—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–Ω—è (noisereduce –∞–±–æ spectral gating)"""
        if self.noisereduce is not None:
            try:
                # NoiseReduce (CPU, –∞–ª–µ —à–≤–∏–¥–∫–∏–π)
                result = self.noisereduce.reduce_noise(
                    y=audio,
                    sr=self.sample_rate,
                    stationary=True,
                    prop_decrease=0.8
                )
                print(f"{Fore.CYAN}üéõÔ∏è  NoiseReduce –∑–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–æ")
                return result.astype(np.float32)
            except Exception as e:
                print(f"{Fore.YELLOW}‚ö†Ô∏è  NoiseReduce –ø–æ–º–∏–ª–∫–∞: {e}")
        
        # Fallback: Spectral Gating (GPU)
        return self.spectral_gate_denoise(audio)
    
    def process_audio(self, audio, use_vad=True, use_deepfilter=True, use_wiener=True):
        """–ü–æ–≤–Ω–∏–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–æ–±–∫–∏ –∞—É–¥—ñ–æ"""
        print(f"{Fore.CYAN}üîß –û–±—Ä–æ–±–∫–∞ –∞—É–¥—ñ–æ...")
        
        # 1. VAD (–≤–∏–¥–∞–ª–µ–Ω–Ω—è —Ç–∏—à—ñ)
        if use_vad:
            audio = self.remove_silence_vad(audio)
        
        # 2. –ê–¥–∞–ø—Ç–∏–≤–Ω–∏–π Wiener (–Ω–∞–π–∫—Ä–∞—â–µ –¥–ª—è –∫—ñ–º–Ω–∞—Ç–Ω–æ–≥–æ —à—É–º—É)
        if use_wiener and self.device == 'cuda':
            audio = self.adaptive_wiener_filter(audio)
        
        # 3. Spectral Gate –∞–±–æ NoiseReduce
        if use_deepfilter:
            audio = self.deepfilter_denoise(audio)
        
        # 4. –ß–∞—Å—Ç–æ—Ç–Ω–∏–π —Ñ—ñ–ª—å—Ç—Ä
        audio = self.apply_bandpass_filter(audio)
        
        # 5. –ö–æ–º–ø—Ä–µ—Å—ñ—è
        audio = self.apply_compression(audio)
        
        # 6. –§—ñ–Ω–∞–ª—å–Ω–∞ –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
        max_val = np.max(np.abs(audio))
        if max_val > 0:
            audio = audio / max_val * 0.95
        
        print(f"{Fore.GREEN}‚úÖ –ê—É–¥—ñ–æ –æ–±—Ä–æ–±–ª–µ–Ω–æ")
        return audio


# –ì–ª–æ–±–∞–ª—å–Ω–∏–π –µ–∫–∑–µ–º–ø–ª—è—Ä —Ñ—ñ–ª—å—Ç—Ä–∞
_audio_filter = None

def get_audio_filter(sample_rate=16000):
    """–û—Ç—Ä–∏–º–∞—Ç–∏ –≥–ª–æ–±–∞–ª—å–Ω–∏–π –µ–∫–∑–µ–º–ø–ª—è—Ä AudioFilter"""
    global _audio_filter
    if _audio_filter is None:
        _audio_filter = AudioFilter(sample_rate)
    return _audio_filter
