# functions/logic_audio.py
"""–†–æ–±–æ—Ç–∞ –∑ –∞—É–¥—ñ–æ"""
import re
import numpy as np
from colorama import Fore
from .config import (
    VOLUME_THRESHOLD, MIN_COMMAND_LENGTH, IGNORE_PHRASES, 
    WHISPER_CORRECTIONS, ACTIVATION_WORD, ACTIVATION_SIMILARITY_THRESHOLD
)

def check_volume(audio):
    """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ —î –∑–≤—É–∫ (–Ω–µ —Ç–∏—à–∞)"""
    return np.abs(audio).mean() > VOLUME_THRESHOLD

def should_ignore_command(text):
    """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ –∫–æ–º–∞–Ω–¥—É –ø–æ—Ç—Ä—ñ–±–Ω–æ —ñ–≥–Ω–æ—Ä—É–≤–∞—Ç–∏"""
    if not text or not text.strip():
        return True
    
    # –û—á–∏—Å—Ç–∏—Ç–∏ —Ç–µ–∫—Å—Ç
    cleaned = text.strip().lower()
    cleaned = re.sub(r'[^\w\s–∞-—è“ë—î—ñ—ó]', '', cleaned, flags=re.IGNORECASE)
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –¥–æ–≤–∂–∏–Ω—É (–±–µ–∑ –ø—Ä–æ–±—ñ–ª—ñ–≤)
    text_without_spaces = re.sub(r'\s+', '', cleaned)
    if len(text_without_spaces) < MIN_COMMAND_LENGTH:
        return True
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ —Ü–µ —ñ–≥–Ω–æ—Ä–æ–≤–∞–Ω–∞ —Ñ—Ä–∞–∑–∞
    for phrase in IGNORE_PHRASES:
        phrase_lower = phrase.lower().strip()
        if phrase_lower in cleaned:
            if cleaned == phrase_lower or \
               cleaned.startswith(phrase_lower + " ") or \
               cleaned.endswith(" " + phrase_lower) or \
               f" {phrase_lower} " in f" {cleaned} ":
                return True
    
    # –Ø–∫—â–æ —Ç–µ–∫—Å—Ç –º—ñ—Å—Ç–∏—Ç—å –ª–∏—à–µ —Ü–∏—Ñ—Ä–∏ –∞–±–æ —Å–∏–º–≤–æ–ª–∏
    if re.match(r'^[\d\s]+$', cleaned):
        return True
    
    return False

def correct_whisper_text(text):
    """–í–∏–ø—Ä–∞–≤–∏—Ç–∏ –ø–æ–º–∏–ª–∫–∏ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è Whisper"""
    text_lower = text.lower()
    
    # –í–∏–ø—Ä–∞–≤–∏—Ç–∏ –ø–æ–º–∏–ª–∫–∏
    for wrong, correct in WHISPER_CORRECTIONS.items():
        if wrong in text_lower:
            text_lower = text_lower.replace(wrong, correct)
    
    # –í—ñ–¥–Ω–æ–≤–∏—Ç–∏ –ø–µ—Ä—à—É –±—É–∫–≤—É –≤–µ–ª–∏–∫—É
    if text_lower and text_lower[0].isalpha():
        text_lower = text_lower[0].upper() + text_lower[1:]
    
    return text_lower

def text_similarity(text1, text2):
    """–û–±—á–∏—Å–ª–∏—Ç–∏ —Å—Ö–æ–∂—ñ—Å—Ç—å –º—ñ–∂ –¥–≤–æ–º–∞ —Ç–µ–∫—Å—Ç–∞–º–∏ (Levenshtein distance)"""
    text1 = text1.lower().strip()
    text2 = text2.lower().strip()
    
    if text1 == text2:
        return 1.0
    
    # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ –æ–¥–Ω–µ —Å–ª–æ–≤–æ –º—ñ—Å—Ç–∏—Ç—å —ñ–Ω—à–µ
    if text1 in text2 or text2 in text1:
        return 0.8
    
    # Levenshtein distance
    def levenshtein_distance(s1, s2):
        if len(s1) < len(s2):
            return levenshtein_distance(s2, s1)
        if len(s2) == 0:
            return len(s1)
        
        previous_row = range(len(s2) + 1)
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]
    
    distance = levenshtein_distance(text1, text2)
    max_len = max(len(text1), len(text2))
    
    if max_len == 0:
        return 1.0
    
    similarity = 1.0 - (distance / max_len)
    return max(0.0, similarity)

def check_activation_word(text):
    """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ —Ç–µ–∫—Å—Ç –º—ñ—Å—Ç–∏—Ç—å –∞–∫—Ç–∏–≤–∞—Ü—ñ–π–Ω–µ —Å–ª–æ–≤–æ"""
    if not ACTIVATION_WORD:
        return True  # üî• –Ø–∫—â–æ –∞–∫—Ç–∏–≤–∞—Ü—ñ—è –≤–∏–º–∫–Ω–µ–Ω–∞ - –∑–∞–≤–∂–¥–∏ true
    
    text_lower = text.lower().strip()
    
    # –Ü–≥–Ω–æ—Ä—É–≤–∞—Ç–∏ –¥—É–∂–µ –∫–æ—Ä–æ—Ç–∫—ñ —Ç–µ–∫—Å—Ç–∏
    if len(text_lower) < 2:
        return False
    
    words = text_lower.split()
    activation_word_lower = ACTIVATION_WORD.lower()
    
    # üî• –ù–û–í–ò–ô: –¢–æ—á–Ω–µ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è —Å–ª–æ–≤–∞
    if activation_word_lower in words:
        return True
    
    # üî• –ù–û–í–ò–ô: –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –ø–æ—á–∞—Ç–∫—É —Ç–µ–∫—Å—Ç—É
    if text_lower.startswith(activation_word_lower + " "):
        return True
    
    # –°—Ç–∞—Ä–∞ –ª–æ–≥—ñ–∫–∞ –∑ similarity –¥–ª—è –ø–æ–º–∏–ª–æ–∫ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è
    min_length = max(2, len(activation_word_lower) - 2)
    
    for word in words:
        if len(word) < min_length:
            continue
            
        similarity = text_similarity(word, activation_word_lower)
        if similarity >= ACTIVATION_SIMILARITY_THRESHOLD:
            return True
    
    return False

def remove_activation_word(text):
    """–í–∏–¥–∞–ª–∏—Ç–∏ –∞–∫—Ç–∏–≤–∞—Ü—ñ–π–Ω–µ —Å–ª–æ–≤–æ –∑ —Ç–µ–∫—Å—Ç—É"""
    if not ACTIVATION_WORD:
        return text
    
    activation_lower = ACTIVATION_WORD.lower()
    text_lower = text.lower()
    
    # üî• –ù–û–í–ò–ô: –¢–æ—á–Ω–µ –≤–∏–¥–∞–ª–µ–Ω–Ω—è –Ω–∞ –ø–æ—á–∞—Ç–∫—É
    if text_lower.startswith(activation_lower + " "):
        result = text[len(activation_lower):].strip()
        return result
    
    if text_lower.startswith(activation_lower + ","):
        result = text[len(activation_lower) + 1:].strip()
        return result
    
    # –í–∏–¥–∞–ª–∏—Ç–∏ —è–∫ –æ–∫—Ä–µ–º–µ —Å–ª–æ–≤–æ
    words = text.split()
    filtered_words = []
    
    for word in words:
        word_lower = word.lower().strip(',.!?;:')
        
        # –¢–æ—á–Ω–µ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è
        if word_lower == activation_lower:
            continue
        
        # Similarity –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞
        similarity = text_similarity(word_lower, activation_lower)
        if similarity < ACTIVATION_SIMILARITY_THRESHOLD:
            filtered_words.append(word)
    
    result = " ".join(filtered_words).strip()
    
    # üî• –ù–û–í–ò–ô: –Ø–∫—â–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Ä–æ–∂–Ω—ñ–π, –ø–æ–≤–µ—Ä–Ω—É—Ç–∏ –æ—Ä–∏–≥—ñ–Ω–∞–ª –±–µ–∑ –ø–µ—Ä—à–æ–≥–æ —Å–ª–æ–≤–∞
    if not result and len(words) > 1:
        return " ".join(words[1:]).strip()
    
    return result if result else text