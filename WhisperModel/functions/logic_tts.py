# functions/logic_tts.py
"""–ú–æ–¥—É–ª—å TTS –Ω–∞ –±–∞–∑—ñ StyleTTS2 Ukrainian (patriotyk)"""
import os
import sys
import time
import hashlib
import threading
import subprocess
from pathlib import Path
from colorama import Fore
import numpy as np
import sounddevice as sd
import soundfile as sf
import torch

class TTSEngine:
    """–î–≤–∏–≥—É–Ω TTS –¥–ª—è —Å–∏–Ω—Ç–µ–∑—É –º–æ–≤–ª–µ–Ω–Ω—è"""
    
    def __init__(self, config=None, listener=None):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è TTS –¥–≤–∏–≥—É–Ω–∞"""
        from .config import (
            TTS_ENABLED, TTS_DEVICE, TTS_CACHE_DIR, TTS_VOICES_DIR,
            TTS_DEFAULT_VOICE, TTS_SPEECH_RATE, TTS_VOLUME
        )
        
        self.enabled = TTS_ENABLED
        if not self.enabled:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  TTS –≤–∏–º–∫–Ω–µ–Ω–æ")
            self.is_ready = False
            return
        
        self.listener = listener
        self.is_ready = False
        self.is_playing = False
        
        # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
        self.device = TTS_DEVICE
        self.cache_dir = Path(TTS_CACHE_DIR)
        self.voices_dir = Path(TTS_VOICES_DIR)
        self.default_voice = TTS_DEFAULT_VOICE
        self.speech_rate = TTS_SPEECH_RATE
        self.volume = TTS_VOLUME
        
        # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π
        self.cache_dir.mkdir(exist_ok=True, parents=True)
        self.voices_dir.mkdir(exist_ok=True, parents=True)
        
        # –ú–æ–¥–µ–ª—å —Ç–∞ –≥–æ–ª–æ—Å–∏
        self.model = None
        self.available_voices = {}
        self.style_vectors = {}
        
        print(f"{Fore.CYAN}üîä –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è TTS (StyleTTS2 Ukrainian)...")
        print(f"{Fore.CYAN}   –ü—Ä–∏—Å—Ç—Ä—ñ–π: {self.device}")
        
        try:
            self._install_dependencies()
            self._discover_voices()
            self._load_model()
            self.is_ready = True
            print(f"{Fore.GREEN}‚úÖ TTS –≥–æ—Ç–æ–≤–∏–π")
        except Exception as e:
            print(f"{Fore.RED}‚ùå –ü–æ–º–∏–ª–∫–∞ TTS: {e}")
            import traceback
            traceback.print_exc()
            self.is_ready = False
    
    def _install_dependencies(self):
        """–í—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ"""
        print(f"{Fore.CYAN}üì¶ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π...")
        
        deps = [
            "styletts2-inference",
            "ukrainian-word-stress",
            "ipa-uk",
            "unicodedata2"
        ]
        
        for dep in deps:
            try:
                if dep == "styletts2-inference":
                    from styletts2_inference.models import StyleTTS2
                elif dep == "ukrainian-word-stress":
                    from ukrainian_word_stress import Stressifier
                elif dep == "ipa-uk":
                    from ipa_uk import ipa
                else:
                    __import__(dep.replace("-", "_"))
            except ImportError:
                print(f"{Fore.YELLOW}   –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è {dep}...")
                subprocess.check_call([
                    sys.executable, "-m", "pip", "install", dep
                ])
        
        print(f"{Fore.GREEN}‚úÖ –ó–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ –≥–æ—Ç–æ–≤—ñ")
    
    def _discover_voices(self):
        """–ó–Ω–∞–π—Ç–∏ –≥–æ–ª–æ—Å–∏ (.pt —Ñ–∞–π–ª–∏)"""
        self.available_voices.clear()
        
        if not self.voices_dir.exists():
            print(f"{Fore.YELLOW}‚ö†Ô∏è  –ü–∞–ø–∫–∞ –≥–æ–ª–æ—Å—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞: {self.voices_dir}")
            return
        
        # –®—É–∫–∞—î–º–æ .pt —Ñ–∞–π–ª–∏
        pt_files = list(self.voices_dir.glob("*.pt"))
        
        for pt_file in pt_files:
            voice_name = pt_file.stem
            self.available_voices[voice_name] = pt_file
            print(f"{Fore.CYAN}   üéµ –ì–æ–ª–æ—Å: {voice_name}")
        
        if not self.available_voices:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  –ì–æ–ª–æ—Å–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
            print(f"{Fore.YELLOW}   üí° –ü–æ–º—ñ—Å—Ç—ñ—Ç—å .pt —Ñ–∞–π–ª–∏ –≤ {self.voices_dir}")
        else:
            print(f"{Fore.GREEN}‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ –≥–æ–ª–æ—Å—ñ–≤: {len(self.available_voices)}")
            if self.default_voice not in self.available_voices:
                self.default_voice = list(self.available_voices.keys())[0]
    
    def _load_model(self):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å StyleTTS2"""
        print(f"{Fore.CYAN}üîß –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ...")
        
        try:
            from styletts2_inference.models import StyleTTS2
            
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ MULTISPEAKER –º–æ–¥–µ–ª—å
            print(f"{Fore.CYAN}   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è multispeaker –º–æ–¥–µ–ª—ñ...")
            self.model = StyleTTS2(
                hf_path='patriotyk/styletts2_ukrainian_multispeaker',
                device=self.device
            )
            
            print(f"{Fore.GREEN}‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞")
            
            # –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å—Ç–∏–ª—ñ
            self._load_style_vectors()
            
        except Exception as e:
            print(f"{Fore.RED}‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {e}")
            raise
    
    def _load_style_vectors(self):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å—Ç–∏–ª—ñ –≥–æ–ª–æ—Å—ñ–≤"""
        if not self.available_voices:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  –ù–µ–º–∞—î –≥–æ–ª–æ—Å—ñ–≤ –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è")
            return
        
        print(f"{Fore.CYAN}üìÇ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Å—Ç–∏–ª—ñ–≤...")
        
        for voice_name, pt_path in self.available_voices.items():
            try:
                style_vector = torch.load(pt_path, map_location=self.device)
                self.style_vectors[voice_name] = style_vector
                print(f"{Fore.GREEN}   ‚úÖ {voice_name}")
            except Exception as e:
                print(f"{Fore.RED}   ‚ùå {voice_name}: {e}")
        
        print(f"{Fore.GREEN}‚úÖ –°—Ç–∏–ª—ñ–≤ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: {len(self.style_vectors)}")
    
    def _preprocess_text(self, text):
        """–ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ —Ç–µ–∫—Å—Ç (–Ω–∞–≥–æ–ª–æ—Å–∏ + IPA)"""
        try:
            from ukrainian_word_stress import Stressifier, StressSymbol
            from ipa_uk import ipa
            from unicodedata import normalize
            import re
            
            # –û—á–∏—Å—Ç–∏—Ç–∏
            text = text.strip().replace('"', '')
            if not text:
                return ""
            
            # –ù–∞–≥–æ–ª–æ—Å–∏
            stressify = Stressifier()
            text = text.replace('+', StressSymbol.CombiningAcuteAccent)
            text = normalize('NFKC', text)
            
            # –¢–∏—Ä–µ
            text = re.sub(r'[·†Ü‚Äê‚Äë‚Äí‚Äì‚Äî‚Äï‚Åª‚Çã‚àí‚∏∫‚∏ª]', '-', text)
            text = re.sub(r' - ', ': ', text)
            
            # IPA —Ñ–æ–Ω–µ—Ç–∏–∫–∞
            phonetic = ipa(stressify(text))
            
            return phonetic
            
        except Exception as e:
            print(f"{Fore.YELLOW}‚ö†Ô∏è  –ü–æ–º–∏–ª–∫–∞ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å–∏–Ω–≥—É: {e}")
            return text
    
    def _split_to_parts(self, text):
        """–†–æ–∑–±–∏—Ç–∏ —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏"""
        split_symbols = '.?!:'
        parts = ['']
        index = 0
        
        for s in text:
            parts[index] += s
            if s in split_symbols and len(parts[index]) > 150:
                index += 1
                parts.append('')
        
        return [p.strip() for p in parts if p.strip()]
    
    def _get_cache_key(self, text, voice_name, rate):
        """–ö–ª—é—á –∫–µ—à—É"""
        key_string = f"{text}|{voice_name}|{rate:.2f}"
        key_hash = hashlib.md5(key_string.encode('utf-8')).hexdigest()
        
        cache_subdir = self.cache_dir / key_hash[:2]
        cache_subdir.mkdir(exist_ok=True)
        
        return cache_subdir / f"{key_hash}.wav"
    
    def _pause_recording(self):
        """–ü—Ä–∏–∑—É–ø–∏–Ω–∏—Ç–∏ –∑–∞–ø–∏—Å"""
        if self.listener and hasattr(self.listener, 'pause_listening'):
            return self.listener.pause_listening()
        return False
    
    def _resume_recording(self):
        """–í—ñ–¥–Ω–æ–≤–∏—Ç–∏ –∑–∞–ø–∏—Å"""
        if self.listener and hasattr(self.listener, 'resume_listening'):
            return self.listener.resume_listening()
        return False
    
    def synthesize(self, text, voice_name=None, rate=None):
        """–°–∏–Ω—Ç–µ–∑—É–≤–∞—Ç–∏ —Ç–µ–∫—Å—Ç"""
        if not self.is_ready or not self.model:
            print(f"{Fore.RED}‚ùå TTS –Ω–µ –≥–æ—Ç–æ–≤–∏–π")
            return None
        
        if voice_name is None:
            voice_name = self.default_voice
        if rate is None:
            rate = self.speech_rate
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –∫–µ—à
        cache_path = self._get_cache_key(text, voice_name, rate)
        if cache_path.exists():
            print(f"{Fore.GREEN}‚ôªÔ∏è  –ö–µ—à")
            return cache_path
        
        print(f"{Fore.CYAN}üîä –°–∏–Ω—Ç–µ–∑: '{text[:50]}...' [{voice_name}]")
        
        try:
            # –û—Ç—Ä–∏–º–∞—Ç–∏ —Å—Ç–∏–ª—å
            if voice_name not in self.style_vectors:
                print(f"{Fore.RED}‚ùå –ì–æ–ª–æ—Å –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {voice_name}")
                return None
            
            style = self.style_vectors[voice_name]
            
            # –†–æ–∑–±–∏—Ç–∏ –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏
            parts = self._split_to_parts(text)
            
            result_wav = []
            
            for part in parts:
                # –ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ —Ç–µ–∫—Å—Ç
                phonetic = self._preprocess_text(part)
                
                if not phonetic:
                    continue
                
                # –¢–æ–∫–µ–Ω—ñ–∑—É–≤–∞—Ç–∏
                tokens = self.model.tokenizer.encode(phonetic)
                
                # –°–∏–Ω—Ç–µ–∑
                wav = self.model(tokens, speed=rate, s_prev=style)
                result_wav.append(wav)
            
            if not result_wav:
                print(f"{Fore.RED}‚ùå –ü–æ—Ä–æ–∂–Ω—ñ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
                return None
            
            # –û–±'—î–¥–Ω–∞—Ç–∏
            audio = torch.concatenate(result_wav).cpu().numpy()
            
            # –ó–±–µ—Ä–µ–≥—Ç–∏
            sf.write(str(cache_path), audio, 24000)
            print(f"{Fore.GREEN}‚úÖ –°–∏–Ω—Ç–µ–∑–æ–≤–∞–Ω–æ")
            
            return cache_path
            
        except Exception as e:
            print(f"{Fore.RED}‚ùå –ü–æ–º–∏–ª–∫–∞ —Å–∏–Ω—Ç–µ–∑—É: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def speak(self, text, voice_name=None, rate=None, wait=True):
        """–û–∑–≤—É—á–∏—Ç–∏ —Ç–µ–∫—Å—Ç"""
        if not self.enabled or not self.is_ready:
            return False
        
        if not text or len(text.strip()) == 0:
            return False
        
        # –ü—Ä–∏–∑—É–ø–∏–Ω–∏—Ç–∏ –∑–∞–ø–∏—Å
        was_recording = self._pause_recording()
        
        try:
            # –°–∏–Ω—Ç–µ–∑—É–≤–∞—Ç–∏
            audio_path = self.synthesize(text, voice_name, rate)
            if not audio_path or not audio_path.exists():
                return False
            
            # –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏
            audio_data, sample_rate = sf.read(str(audio_path), dtype='float32')
            audio_data = audio_data * self.volume
            
            # –í—ñ–¥—Ç–≤–æ—Ä–∏—Ç–∏
            duration = len(audio_data) / sample_rate
            print(f"{Fore.CYAN}üîä –í—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è ({duration:.1f}—Å)...")
            self.is_playing = True
            
            if wait:
                sd.play(audio_data, sample_rate)
                sd.wait()
                self.is_playing = False
            else:
                def play_async():
                    sd.play(audio_data, sample_rate)
                    sd.wait()
                    self.is_playing = False
                
                thread = threading.Thread(target=play_async, daemon=True)
                thread.start()
            
            return True
            
        except Exception as e:
            print(f"{Fore.RED}‚ùå –ü–æ–º–∏–ª–∫–∞ –≤—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è: {e}")
            return False
            
        finally:
            if was_recording:
                self._resume_recording()
    
    def stop(self):
        """–ó—É–ø–∏–Ω–∏—Ç–∏ –≤—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è"""
        if self.is_playing:
            sd.stop()
            self.is_playing = False
    
    def get_voices(self):
        """–°–ø–∏—Å–æ–∫ –≥–æ–ª–æ—Å—ñ–≤"""
        return list(self.available_voices.keys())
    
    def set_voice(self, voice_name):
        """–í—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ –≥–æ–ª–æ—Å"""
        if voice_name in self.available_voices:
            self.default_voice = voice_name
            return True
        return False
    
    def set_rate(self, rate):
        """–í—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ —à–≤–∏–¥–∫—ñ—Å—Ç—å"""
        if 0.5 <= rate <= 2.0:
            self.speech_rate = rate
            return True
        return False
    
    def set_volume(self, volume):
        """–í—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ –≥—É—á–Ω—ñ—Å—Ç—å"""
        if 0.0 <= volume <= 1.0:
            self.volume = volume
            return True
        return False


# –ì–ª–æ–±–∞–ª—å–Ω–∏–π –µ–∫–∑–µ–º–ø–ª—è—Ä
_tts_engine = None

def get_tts_engine(listener=None):
    """–û—Ç—Ä–∏–º–∞—Ç–∏ TTS engine"""
    global _tts_engine
    if _tts_engine is None:
        _tts_engine = TTSEngine(listener=listener)
    return _tts_engine

def init_tts(listener=None):
    """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ TTS"""
    global _tts_engine
    if _tts_engine is None:
        _tts_engine = TTSEngine(listener=listener)
    return _tts_engine