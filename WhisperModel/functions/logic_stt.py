# functions/logic_stt.py
"""–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π –º–æ–¥—É–ª—å —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –º–æ–≤–∏ –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é Whisper —Ç–∞ w2v-bert"""
import numpy as np
import torch  # –Ü–º–ø–æ—Ä—Ç torch —Ç—É—Ç
import threading
from queue import Queue
from colorama import Fore
from .config import (
    STT_MODEL_TYPE, STT_MODEL_ID, STT_DEVICE, STT_LANGUAGE,
    STT_PARALLEL_ENABLED, STT_CONFIDENCE_THRESHOLD,
    WHISPER_COMPUTE_TYPE, WHISPER_BATCH_SIZE,
    W2V_BERT_MODEL_NAME
)

class STTEngine:
    """–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π –¥–≤–∏–≥—É–Ω —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –º–æ–≤–∏"""
    
    def __init__(self):
        # –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –ø—Ä–∏—Å—Ç—Ä–æ—é –¥–∏–Ω–∞–º—ñ—á–Ω–æ
        self.device = self._determine_device()
        
        self.models = {}
        self.results_queue = Queue()
        
        print(f"{Fore.CYAN}üîä –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è STT –¥–≤–∏–≥—É–Ω–∞...")
        print(f"{Fore.CYAN}   –¢–∏–ø: {STT_MODEL_TYPE}, –ü—Ä–∏—Å—Ç—Ä—ñ–π: {self.device}")
        
        self._load_models()
    
    def _determine_device(self):
        """–í–∏–∑–Ω–∞—á–∏—Ç–∏ –ø—Ä–∏—Å—Ç—Ä—ñ–π –¥–ª—è –æ–±—á–∏—Å–ª–µ–Ω—å"""
        if STT_DEVICE == "auto":
            if torch.cuda.is_available():
                return "cuda"
            else:
                return "cpu"
        elif STT_DEVICE == "cuda":
            if torch.cuda.is_available():
                return "cuda"
            else:
                print(f"{Fore.YELLOW}‚ö†Ô∏è  CUDA –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é CPU")
                return "cpu"
        else:
            return STT_DEVICE
    
    def _load_models(self):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –≤–∫–∞–∑–∞–Ω—ñ –º–æ–¥–µ–ª—ñ"""
        if STT_MODEL_TYPE in ["whisper", "both"]:
            self._load_whisper()
        
        if STT_MODEL_TYPE in ["w2v-bert", "both"]:
            self._load_w2v_bert()
    
    def _load_whisper(self):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ Whisper –º–æ–¥–µ–ª—å"""
        try:
            import whisper
            
            print(f"{Fore.CYAN}   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è Whisper {STT_MODEL_ID}...")
            
            # –í–∏–∑–Ω–∞—á–∏—Ç–∏ –ø—Ä–∏—Å—Ç—Ä—ñ–π –¥–ª—è Whisper
            device = "cuda" if self.device == "cuda" else "cpu"
            
            model = whisper.load_model(
                STT_MODEL_ID,
                device=device
            )
            
            self.models["whisper"] = {
                "model": model,
                "type": "whisper",
                "id": STT_MODEL_ID,
                "device": device
            }
            
            print(f"{Fore.GREEN}   ‚úÖ Whisper –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –Ω–∞ {device}")
            
        except Exception as e:
            print(f"{Fore.RED}   ‚ùå –ü–æ–º–∏–ª–∫–∞ Whisper: {e}")
            import traceback
            traceback.print_exc()
    
    def _load_w2v_bert(self):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ w2v-bert –º–æ–¥–µ–ª—å"""
        try:
            from transformers import Wav2Vec2BertForCTC, AutoProcessor
            
            print(f"{Fore.CYAN}   –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è w2v-bert...")
            
            processor = AutoProcessor.from_pretrained(W2V_BERT_MODEL_NAME)
            model = Wav2Vec2BertForCTC.from_pretrained(W2V_BERT_MODEL_NAME)
            
            # –ü–µ—Ä–µ–Ω–µ—Å—Ç–∏ –Ω–∞ –ø–æ—Ç—Ä—ñ–±–Ω–∏–π –ø—Ä–∏—Å—Ç—Ä—ñ–π
            if self.device == "cuda":
                model = model.to("cuda")
            model.eval()
            
            self.models["w2v-bert"] = {
                "model": model,
                "processor": processor,
                "type": "w2v-bert",
                "id": W2V_BERT_MODEL_NAME,
                "device": self.device
            }
            
            print(f"{Fore.GREEN}   ‚úÖ w2v-bert –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –Ω–∞ {self.device}")
            
        except Exception as e:
            print(f"{Fore.RED}   ‚ùå –ü–æ–º–∏–ª–∫–∞ w2v-bert: {e}")
            import traceback
            traceback.print_exc()
    
    def transcribe_whisper(self, audio):
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É–≤–∞—Ç–∏ —á–µ—Ä–µ–∑ Whisper"""
        try:
            model_info = self.models["whisper"]
            model = model_info["model"]
            
            # –ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ –∞—É–¥—ñ–æ
            audio_tensor = torch.from_numpy(audio).float()
            
            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É–≤–∞—Ç–∏
            result = model.transcribe(
                audio_tensor,
                language=STT_LANGUAGE,
                fp16=(WHISPER_COMPUTE_TYPE == "float16") and (self.device == "cuda"),
                task="transcribe"
            )
            
            return {
                "text": result["text"].strip(),
                "confidence": np.mean([seg.get("confidence", 0.9) for seg in result.get("segments", [])]),
                "model": "whisper"
            }
            
        except Exception as e:
            print(f"{Fore.RED}   ‚ùå Whisper —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def transcribe_w2v_bert(self, audio):
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É–≤–∞—Ç–∏ —á–µ—Ä–µ–∑ w2v-bert"""
        try:
            model_info = self.models["w2v-bert"]
            model = model_info["model"]
            processor = model_info["processor"]
            
            # –ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ –∞—É–¥—ñ–æ
            audio_tensor = torch.from_numpy(audio).float()
            
            # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è
            if torch.max(torch.abs(audio_tensor)) > 0:
                audio_tensor = audio_tensor / torch.max(torch.abs(audio_tensor))
            
            # –û–±—Ä–æ–±–∏—Ç–∏ –ø—Ä–æ—Ü–µ—Å–æ—Ä–æ–º
            inputs = processor(
                audio_tensor.numpy(), 
                sampling_rate=16000, 
                return_tensors="pt",
                padding=True
            )
            
            # –ó–Ω–∞–π—Ç–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π –∫–ª—é—á –¥–ª—è –≤–≤–æ–¥—É
            input_key = None
            for key in ['input_values', 'input_features']:
                if key in inputs:
                    input_key = key
                    break
            
            if not input_key:
                return None
            
            # –ü–µ—Ä–µ–Ω–µ—Å—Ç–∏ –Ω–∞ –ø—Ä–∏—Å—Ç—Ä—ñ–π
            input_data = inputs[input_key].to(self.device)
            
            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É–≤–∞—Ç–∏
            with torch.no_grad():
                logits = model(input_data).logits
            
            # –û—Ç—Ä–∏–º–∞—Ç–∏ –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å
            probs = torch.softmax(logits, dim=-1)
            confidence = torch.max(probs).item()
            
            # –î–µ–∫–æ–¥—É–≤–∞—Ç–∏
            predicted_ids = torch.argmax(logits, dim=-1)
            text = processor.batch_decode(predicted_ids)[0]
            
            return {
                "text": text.strip(),
                "confidence": confidence,
                "model": "w2v-bert"
            }
            
        except Exception as e:
            print(f"{Fore.RED}   ‚ùå w2v-bert —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _transcribe_parallel(self, audio):
        """–ü–∞—Ä–∞–ª–µ–ª—å–Ω–µ –≤–∏–∫–æ–Ω–∞–Ω–Ω—è –≤—Å—ñ—Ö –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π"""
        threads = []
        
        if "whisper" in self.models:
            thread = threading.Thread(
                target=lambda: self.results_queue.put(self.transcribe_whisper(audio)),
                daemon=True
            )
            threads.append(thread)
        
        if "w2v-bert" in self.models:
            thread = threading.Thread(
                target=lambda: self.results_queue.put(self.transcribe_w2v_bert(audio)),
                daemon=True
            )
            threads.append(thread)
        
        # –ó–∞–ø—É—Å—Ç–∏—Ç–∏ –≤—Å—ñ –ø–æ—Ç–æ–∫–∏
        for thread in threads:
            thread.start()
        
        # –û—á—ñ–∫—É–≤–∞—Ç–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è
        for thread in threads:
            thread.join(timeout=10.0)  # –¢–∞–π–º–∞—É—Ç 10 —Å–µ–∫—É–Ω–¥
        
        # –ó—ñ–±—Ä–∞—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
        results = []
        while not self.results_queue.empty():
            result = self.results_queue.get()
            if result and result["text"]:
                results.append(result)
        
        return results
    
    def _choose_best_result(self, results):
        """–í–∏–±—Ä–∞—Ç–∏ –Ω–∞–π–∫—Ä–∞—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∑ –¥–µ–∫—ñ–ª—å–∫–æ—Ö –º–æ–¥–µ–ª–µ–π"""
        if not results:
            return None
        
        if len(results) == 1:
            return results[0]["text"]
        
        # –í—ñ–¥—Ñ—ñ–ª—å—Ç—Ä—É–≤–∞—Ç–∏ –∑–∞ –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—é
        valid_results = [
            r for r in results 
            if r["confidence"] > STT_CONFIDENCE_THRESHOLD
        ]
        
        if not valid_results:
            # –Ø–∫—â–æ –≤—Å—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –Ω–∏–∑—å–∫–æ—ó —è–∫–æ—Å—Ç—ñ, –±–µ—Ä–µ–º–æ –Ω–∞–π–∫—Ä–∞—â–∏–π
            valid_results = sorted(results, key=lambda x: x["confidence"], reverse=True)[:1]
        
        # –í–∏–±—ñ—Ä –∑–∞ –¥–æ–≤–∂–∏–Ω–æ—é —Ç–∞ –≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—é
        best_result = max(
            valid_results,
            key=lambda x: len(x["text"]) * x["confidence"]
        )
        
        print(f"{Fore.MAGENTA}   üìä –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è:")
        for result in results:
            status = "üèÜ" if result == best_result else "  "
            print(f"{Fore.CYAN}     {status} {result['model']}: '{result['text'][:50]}...' (–≤–ø–µ–≤–Ω–µ–Ω—ñ—Å—Ç—å: {result['confidence']:.2f})")
        
        return best_result["text"]
    
    def transcribe(self, audio):
        """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó"""
        if not self.models:
            print(f"{Fore.RED}   ‚ùå –ù–µ–º–∞—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π")
            return ""
        
        # üî• –í–ò–ü–†–ê–í–õ–ï–ù–û: –î–æ–¥–∞–Ω–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ STT_MODEL_TYPE == "both"
        if STT_PARALLEL_ENABLED and len(self.models) > 1 and STT_MODEL_TYPE == "both":
            # –ü–∞—Ä–∞–ª–µ–ª—å–Ω–∏–π —Ä–µ–∂–∏–º (—Ç—ñ–ª—å–∫–∏ —è–∫—â–æ "both")
            print(f"{Fore.CYAN}   üîÑ –ü–∞—Ä–∞–ª–µ–ª—å–Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è...")
            results = self._transcribe_parallel(audio)
            best_text = self._choose_best_result(results)
            
            if best_text:
                print(f"{Fore.GREEN}   ‚úÖ –û–±—Ä–∞–Ω–æ: '{best_text[:50]}...'")
                return best_text
        
        # –ü–æ—Å–ª—ñ–¥–æ–≤–Ω–∏–π —Ä–µ–∂–∏–º –∞–±–æ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å
        if "whisper" in self.models:
            result = self.transcribe_whisper(audio)
            if result:
                return result["text"]
        
        if "w2v-bert" in self.models:
            result = self.transcribe_w2v_bert(audio)
            if result:
                return result["text"]
        
        return ""
    
    def get_available_models(self):
        """–û—Ç—Ä–∏–º–∞—Ç–∏ —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π"""
        return list(self.models.keys())


# –ì–ª–æ–±–∞–ª—å–Ω–∏–π –µ–∫–∑–µ–º–ø–ª—è—Ä
_stt_engine = None

def get_stt_engine():
    """–û—Ç—Ä–∏–º–∞—Ç–∏ –≥–ª–æ–±–∞–ª—å–Ω–∏–π STT –¥–≤–∏–≥—É–Ω"""
    global _stt_engine
    if _stt_engine is None:
        _stt_engine = STTEngine()
    return _stt_engine