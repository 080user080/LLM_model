# main.py
"""–ì–æ–ª–æ–≤–Ω–∏–π —Ñ–∞–π–ª –∑–∞–ø—É—Å–∫—É"""
import os
import sys
import time
from pathlib import Path
from colorama import Fore, Back, Style, init
import threading

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ colorama
init(autoreset=True)


# –î–æ–¥–∞—Ç–∏ —à–ª—è—Ö–∏ –¥–æ CUDA –±—ñ–±–ª—ñ–æ—Ç–µ–∫
venv_path = sys.prefix
nvidia_paths = [
    os.path.join(venv_path, 'Lib', 'site-packages', 'nvidia', 'cublas', 'bin'),
    os.path.join(venv_path, 'Lib', 'site-packages', 'nvidia', 'cudnn', 'bin'),
    os.path.join(venv_path, 'Lib', 'site-packages', 'nvidia', 'cuda_runtime', 'bin'),
]

for path in nvidia_paths:
    if os.path.exists(path):
        os.environ['PATH'] = path + os.pathsep + os.environ['PATH']
        try:
            os.add_dll_directory(path)
        except:
            pass

import sounddevice as sd
import numpy as np
import torch
from transformers import Wav2Vec2BertForCTC, AutoProcessor
import requests

# –Ü–º–ø–æ—Ä—Ç –º–æ–¥—É–ª—ñ–≤
from functions.logic_core import FunctionRegistry
from functions.logic_commands import VoiceAssistant
from functions.logic_audio import (
    should_ignore_command, correct_whisper_text, 
    check_volume, check_activation_word, remove_activation_word,
    text_similarity  # –î–æ–¥–∞–π—Ç–µ —Ü–µ–π —ñ–º–ø–æ—Ä—Ç
)
from functions.config import (
    SAMPLE_RATE, LISTEN_DURATION, VOLUME_THRESHOLD,
    ACTIVATION_WORD, ACTIVATION_LISTEN_DURATION, COMMAND_LISTEN_DURATION, MICROPHONE_DEVICE_ID  # üëà –î–û–î–ê–ô–¢–ï
)
# –î–æ–¥–∞–π—Ç–µ –≤ —ñ–º–ø–æ—Ä—Ç–∏ –≤ main.py —Ç–∞ aaa_voice_input.py:
from functions.config import MICROPHONE_DEVICE_ID

# üëá –î–û–î–ê–ô–¢–ï –¢–£–¢
print("\n" + "="*60)
print("üé§ –î–û–°–¢–£–ü–ù–Ü –ú–Ü–ö–†–û–§–û–ù–ò:")
print("="*60)
print(sd.query_devices())
print("="*60 + "\n")

# üëá –î–û–î–ê–ô–¢–ï –¶–ï
if MICROPHONE_DEVICE_ID is not None:
    print(f"{Fore.YELLOW}üé§ –í–∏–±—Ä–∞–Ω–æ –º—ñ–∫—Ä–æ—Ñ–æ–Ω #{MICROPHONE_DEVICE_ID}")
    device_info = sd.query_devices(MICROPHONE_DEVICE_ID)
    print(f"   –ù–∞–∑–≤–∞: {device_info['name']}")
    print(f"   –ö–∞–Ω–∞–ª–∏: {device_info['max_input_channels']}")
else:
    print(f"{Fore.YELLOW}üé§ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è —Å–∏—Å—Ç–µ–º–Ω–∏–π –º—ñ–∫—Ä–æ—Ñ–æ–Ω –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º")
    default_input = sd.query_devices(kind='input')
    print(f"   –ù–∞–∑–≤–∞: {default_input['name']}")
print()

# –í main.py –ø—ñ—Å–ª—è –≤–∏–≤–æ–¥—É –º—ñ–∫—Ä–æ—Ñ–æ–Ω—ñ–≤
print("üß™ –¢–µ—Å—Ç–æ–≤–∏–π –∑–∞–ø–∏—Å 2 —Å–µ–∫—É–Ω–¥–∏...")
test_audio = sd.rec(
    int(2 * SAMPLE_RATE),
    samplerate=SAMPLE_RATE,
    channels=1,
    dtype=np.float32,
    device=MICROPHONE_DEVICE_ID,
    blocking=True
)
volume = np.abs(test_audio).mean()
print(f"   –°–µ—Ä–µ–¥–Ω—è –≥—É—á–Ω—ñ—Å—Ç—å: {volume:.6f}")
print(f"   –ü–æ—Ä—ñ–≥: {VOLUME_THRESHOLD}")
if volume > VOLUME_THRESHOLD:
    print(f"   ‚úÖ –ú—ñ–∫—Ä–æ—Ñ–æ–Ω –ø—Ä–∞—Ü—é—î!")
else:
    print(f"   ‚ùå –ó–∞–Ω–∞–¥—Ç–æ —Ç–∏—Ö–æ –∞–±–æ –º—ñ–∫—Ä–æ—Ñ–æ–Ω –Ω–µ –ø—Ä–∞—Ü—é—î")
print()

def load_w2v_model():
    """–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ w2v-bert-uk –º–æ–¥–µ–ª—å"""
    try:
        model_name = 'Yehor/w2v-bert-uk-v2.1'
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        print(f"   üîß –ú–æ–¥–µ–ª—å: {model_name}")
        print(f"   üéØ –ü—Ä–∏—Å—Ç—Ä—ñ–π: {device}")
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –ø—Ä–æ—Ü–µ—Å–æ—Ä
        processor = AutoProcessor.from_pretrained(model_name)
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å
        model = Wav2Vec2BertForCTC.from_pretrained(model_name)
        model = model.to(device)
        model.eval()
        
        print(f"   ‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞")
        
        return model, processor, device
        
    except Exception as e:
        print(f"   ‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ: {e}")
        raise

def transcribe_audio(audio, model, processor, device):
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É–≤–∞—Ç–∏ –∞—É–¥—ñ–æ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é w2v-bert-uk"""
    try:
        # –ö–æ–Ω–≤–µ—Ä—Ç—É–≤–∞—Ç–∏ –∞—É–¥—ñ–æ –≤ —Ç–µ–Ω–∑–æ—Ä
        audio_tensor = torch.from_numpy(audio).float()
        
        # –ù–æ—Ä–º–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –∞—É–¥—ñ–æ
        if torch.max(torch.abs(audio_tensor)) > 0:
            audio_tensor = audio_tensor / torch.max(torch.abs(audio_tensor))
        
        # –û–±—Ä–æ–±–∏—Ç–∏ –ø—Ä–æ—Ü–µ—Å–æ—Ä–æ–º
        inputs = processor(
            audio_tensor.numpy(), 
            sampling_rate=SAMPLE_RATE, 
            return_tensors="pt",
            padding=True
        )
        
        # –ó–Ω–∞–π—Ç–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π –∫–ª—é—á –¥–ª—è –≤–≤–æ–¥—É
        input_key = None
        for key in ['input_values', 'input_features']:
            if key in inputs:
                input_key = key
                break
        
        if not input_key:
            print(f"{Fore.RED}   ‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∫–ª—é—á –¥–ª—è –≤–≤–æ–¥—É")
            return ""
        
        # –ü–µ—Ä–µ–Ω–µ—Å—Ç–∏ –Ω–∞ –ø—Ä–∏—Å—Ç—Ä—ñ–π
        input_data = inputs[input_key].to(device)
        
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É–≤–∞—Ç–∏
        with torch.no_grad():
            logits = model(input_data).logits
        
        # –î–µ–∫–æ–¥—É–≤–∞—Ç–∏
        predicted_ids = torch.argmax(logits, dim=-1)
        text = processor.batch_decode(predicted_ids)[0]
        
        return text.strip()
        
    except Exception as e:
        print(f"{Fore.RED}   ‚ùå –ü–æ–º–∏–ª–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó: {e}")
        return ""

def record_audio_with_countdown(duration, sample_rate, label="–ó–∞–ø–∏—Å"):
    """–ó–∞–ø–∏—Å–∞—Ç–∏ –∞—É–¥—ñ–æ –∑ –∑–≤–æ—Ä–æ—Ç–Ω—ñ–º –≤—ñ–¥–ª—ñ–∫–æ–º"""
    print(f"{Fore.CYAN}üé§ {label}: ", end="", flush=True)
    
    # –°—Ç–≤–æ—Ä–∏—Ç–∏ –∑–º—ñ–Ω–Ω—É –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ
    audio_data = []
    
    def callback(indata, frames, time_info, status):
        audio_data.append(indata.copy())
    
    # –ó–∞–ø—É—Å—Ç–∏—Ç–∏ –∑–∞–ø–∏—Å –≤ –æ–∫—Ä–µ–º–æ–º—É –ø–æ—Ç–æ—Ü—ñ
    stream = sd.InputStream(
        samplerate=sample_rate,
        channels=1,
        dtype=np.float32,
        device=MICROPHONE_DEVICE_ID,  # üëà –î–û–î–ê–¢–ò
        callback=callback
    )
    
    stream.start()
    
    # –ó–≤–æ—Ä–æ—Ç–Ω—ñ–π –≤—ñ–¥–ª—ñ–∫
    for i in range(duration, 0, -1):
        print(f"{Fore.YELLOW}{i}", end="", flush=True)
        time.sleep(1)
        if i > 1:
            print(f"{Fore.LIGHTBLACK_EX}...", end="", flush=True)
    
    stream.stop()
    stream.close()
    
    print(f" {Fore.GREEN}‚úì")
    
    # –û–±'—î–¥–Ω–∞—Ç–∏ –≤—Å—ñ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∏
    if audio_data:
        audio = np.concatenate(audio_data, axis=0)
        return np.squeeze(audio)
    else:
        return np.array([])

def check_lm_studio():
    """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ LM Studio"""
    try:
        response = requests.get("http://localhost:1234/v1/models", timeout=3)
        
        if response.status_code == 200:
            data = response.json()
            if 'data' in data and len(data['data']) > 0:
                model_id = data['data'][0]['id']
                print(f"{Fore.GREEN}‚úÖ –ü—ñ–¥–∫–ª—é—á–µ–Ω–æ –¥–æ LM Studio")
                print(f"{Fore.YELLOW}   üìù –ú–æ–¥–µ–ª—å: {model_id}")
                return True
            else:
                print(f"{Fore.RED}‚ùå LM Studio –∑–∞–ø—É—â–µ–Ω–∏–π, –∞–ª–µ –Ω–µ–º–∞—î –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π!")
                print(f"{Fore.YELLOW}üí° –ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –º–æ–¥–µ–ª—å –≤ LM Studio")
                return False
        else:
            print(f"{Fore.RED}‚ùå LM Studio –≤—ñ–¥–ø–æ–≤—ñ–≤ –∑ –ø–æ–º–∏–ª–∫–æ—é: {response.status_code}")
            return False
            
    except requests.exceptions.Timeout:
        print(f"{Fore.RED}‚ùå LM Studio –Ω–µ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î (timeout)")
        return False
    except requests.exceptions.ConnectionError:
        print(f"{Fore.RED}‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—è –¥–æ LM Studio")
        return False
    except Exception as e:
        print(f"{Fore.RED}‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤—ñ—Ä—Ü—ñ LM Studio: {e}")
        return False

def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –∑–∞–ø—É—Å–∫—É"""
    print(f"{Back.BLUE}{Fore.WHITE}{'='*60}")
    print(f"{Back.BLUE}{Fore.WHITE}ü§ñ –ß—ñ–ø - –ì–æ–ª–æ—Å–æ–≤–∏–π –ê—Å–∏—Å—Ç–µ–Ω—Ç {Style.RESET_ALL}")
    print(f"{Back.BLUE}{Fore.WHITE}{'='*60}{Style.RESET_ALL}")
    
    print(f"\n{Fore.CYAN}üîß –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥—É–ª—ñ–≤...")
    start_time = time.time()
    registry = FunctionRegistry()
    load_time = time.time() - start_time
    print(f"{Fore.LIGHTBLACK_EX}‚è±Ô∏è  {load_time:.2f}—Å")
    
    print(f"\n{Fore.CYAN}üé§ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è w2v-bert-uk...")
    start_time = time.time()
    
    try:
        w2v_model, w2v_processor, device = load_w2v_model()
        w2v_time = time.time() - start_time
        print(f"{Fore.LIGHTBLACK_EX}‚è±Ô∏è  {w2v_time:.2f}—Å")
            
    except Exception as e:
        print(f"{Fore.RED}‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –º–æ–≤–∏")
        print(f"{Fore.RED}   –î–µ—Ç–∞–ª—ñ: {e}")
        return
    
    print(f"\n{Fore.CYAN}üîå –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ LM Studio...")
    if not check_lm_studio():
        return
    
    print(f"\n{Fore.YELLOW}{'='*60}")
    print(f"{Fore.YELLOW}üì¶ –§—É–Ω–∫—Ü—ñ–π: {Fore.WHITE}{len(registry.functions)}")
    for func_name in registry.functions.keys():
        print(f"{Fore.CYAN}   ‚Ä¢ {func_name}")
    print(f"{Fore.YELLOW}{'='*60}{Style.RESET_ALL}")
    
    system_prompt = registry.get_system_prompt()
    assistant = VoiceAssistant(w2v_model, registry, system_prompt)
    
    # –ó–±–µ—Ä–µ–≥—Ç–∏ –º–æ–¥–µ–ª—å —É –∞—Å–∏—Å—Ç–µ–Ω—Ç—ñ
    assistant.w2v_processor = w2v_processor
    assistant.w2v_device = device
    
    # –ü–µ—Ä–µ–¥–∞—Ç–∏ –∞—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤ voice_input –º–æ–¥—É–ª—å
    try:
        from functions.aaa_voice_input import set_assistant
        set_assistant(assistant)
        print(f"{Fore.GREEN}‚úÖ –ê—Å–∏—Å—Ç–µ–Ω—Ç –ø–µ—Ä–µ–¥–∞–Ω–∏–π –≤ voice_input")
    except Exception as e:
        print(f"{Fore.YELLOW}‚ö†Ô∏è  –ù–µ –≤–¥–∞–ª–æ—Å—è –ø–µ—Ä–µ–¥–∞—Ç–∏ –∞—Å–∏—Å—Ç–µ–Ω—Ç–∞: {e}")
    
    # –û—Å–Ω–æ–≤–Ω–∏–π —Ü–∏–∫–ª —Å–ª—É—Ö–∞–Ω–Ω—è
    print(f"\n{Back.CYAN}{Fore.BLACK} üéß –†–ï–ñ–ò–ú –ü–†–û–°–õ–£–•–û–í–£–í–ê–ù–ù–Ø {Style.RESET_ALL}")
    
    if ACTIVATION_WORD:
        print(f"{Fore.YELLOW}üí° –†–µ–∂–∏–º –∞–∫—Ç–∏–≤–∞—Ü—ñ—ó: —Å–∫–∞–∂—ñ—Ç—å '{ACTIVATION_WORD.upper()}' –¥–ª—è –∫–æ–º–∞–Ω–¥–∏")
        print(f"{Fore.LIGHTBLACK_EX}üí° –ü—Ä–∏–∫–ª–∞–¥: '{ACTIVATION_WORD} –≤—ñ–¥–∫—Ä–∏–π –±–ª–æ–∫–Ω–æ—Ç'")
    else:
        print(f"{Fore.YELLOW}üí° –†–µ–∂–∏–º –±–µ–∑ –∞–∫—Ç–∏–≤–∞—Ü—ñ—ó: –≥–æ–≤–æ—Ä—ñ—Ç—å –∫–æ–º–∞–Ω–¥–∏ –Ω–∞–ø—Ä—è–º—É")
        print(f"{Fore.LIGHTBLACK_EX}üí° –ü—Ä–∏–∫–ª–∞–¥: '–≤—ñ–¥–∫—Ä–∏–π –±–ª–æ–∫–Ω–æ—Ç'")
    
    print(f"{Fore.LIGHTBLACK_EX}üí° Ctrl+C –¥–ª—è –≤–∏—Ö–æ–¥—É\n")
    
    while assistant.is_listening:
        try:
            if ACTIVATION_WORD:
                # –†–µ–∂–∏–º –∑ –∞–∫—Ç–∏–≤–∞—Ü—ñ—î—é
                # –°–ª—É—Ö–∞—Ç–∏ –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü—ñ–π–Ω–æ–≥–æ —Å–ª–æ–≤–∞ (–∫–æ—Ä–æ—Ç–∫–æ, –±–µ–∑ –≤—ñ–¥–ª—ñ–∫—É)
                audio = sd.rec(
                    int(ACTIVATION_LISTEN_DURATION * SAMPLE_RATE),
                    samplerate=SAMPLE_RATE,
                    channels=1,
                    dtype=np.float32,
                    device=MICROPHONE_DEVICE_ID,  # üëà –î–û–î–ê–¢–ò
                    blocking=True
                )
                audio = np.squeeze(audio)
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ —î –∑–≤—É–∫
                if not check_volume(audio):
                    continue
                
                # –†–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏
                text = transcribe_audio(audio, w2v_model, w2v_processor, device)
                
                if not text:
                    continue
                
                # –ü–æ–∫–∞–∑–∞—Ç–∏ —â–æ –ø–æ—á—É–ª–∏ (—Å—ñ—Ä–∏–º)
                print(f"{Fore.LIGHTBLACK_EX}üîâ {text}")
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –∞–∫—Ç–∏–≤–∞—Ü—ñ—é
                # –í main.py –∑–Ω–∞–π–¥—ñ—Ç—å –±–ª–æ–∫ –∫–æ–¥—É –ø—ñ—Å–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –∞–∫—Ç–∏–≤–∞—Ü—ñ—ó —Ç–∞ –∑–∞–º—ñ–Ω—ñ—Ç—å –π–æ–≥–æ:

                if check_activation_word(text):
                    print(f"\n{Back.GREEN}{Fore.BLACK} ‚ú® –ê–ö–¢–ò–í–û–í–ê–ù–û! {Style.RESET_ALL}")
                    
                    # –í–∏–¥–∞–ª–∏—Ç–∏ –∞–∫—Ç–∏–≤–∞—Ü—ñ–π–Ω–µ —Å–ª–æ–≤–æ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é —Ñ—É–Ω–∫—Ü—ñ—ó, —è–∫–∞ –≤–∂–µ —î
                    command_text = remove_activation_word(text)
                    
                    # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ —î –∫–æ–º–∞–Ω–¥–∞ –ø—ñ—Å–ª—è –∞–∫—Ç–∏–≤–∞—Ü—ñ–π–Ω–æ–≥–æ —Å–ª–æ–≤–∞
                    has_command = command_text and len(command_text) > 3 and not should_ignore_command(command_text)
                    
                    if has_command:
                        # –ö–æ–º–∞–Ω–¥–∞ –≤–∂–µ —î –≤ –∞–∫—Ç–∏–≤–∞—Ü—ñ–π–Ω—ñ–π —Ñ—Ä–∞–∑—ñ
                        print(f"{Fore.GREEN}‚úì –ö–æ–º–∞–Ω–¥–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω–∞ –≤—ñ–¥—Ä–∞–∑—É")
                        print(f"{Fore.BLUE}üí¨ [–ö–æ–º–∞–Ω–¥–∞]: {Fore.WHITE}{command_text}")
                    else:
                        # –ó–∞–ø–∏—Å–∞—Ç–∏ –∫–æ–º–∞–Ω–¥—É –∑ –≤—ñ–¥–ª—ñ–∫–æ–º
                        print(f"{Fore.YELLOW}‚ö†Ô∏è  –û—á—ñ–∫—É—é –∫–æ–º–∞–Ω–¥—É –ø—ñ—Å–ª—è '{ACTIVATION_WORD}'...")
                        command_audio = record_audio_with_countdown(
                            COMMAND_LISTEN_DURATION, 
                            SAMPLE_RATE,
                            "–ì–æ–≤–æ—Ä—ñ—Ç—å –∫–æ–º–∞–Ω–¥—É"
                        )
                        
                        # –†–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ –∫–æ–º–∞–Ω–¥—É
                        command_text = transcribe_audio(command_audio, w2v_model, w2v_processor, device)
                        
                        if not command_text or should_ignore_command(command_text):
                            print(f"{Fore.YELLOW}‚ö†Ô∏è  –ö–æ–º–∞–Ω–¥—É –Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ\n")
                            continue
                        
                        print(f"{Fore.BLUE}üí¨ [–ö–æ–º–∞–Ω–¥–∞]: {Fore.WHITE}{command_text}")
                    
                    # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ –Ω–µ —ñ–≥–Ω–æ—Ä—É–≤–∞—Ç–∏
                    if should_ignore_command(command_text):
                        print(f"{Fore.LIGHTBLACK_EX}‚è≠Ô∏è  –Ü–≥–Ω–æ—Ä–æ–≤–∞–Ω–æ (—Ñ—ñ–ª—å—Ç—Ä)\n")
                        continue
                    
                    # –ö—É–ª–¥–∞—É–Ω
                    current_time = time.time()
                    if current_time - assistant.last_command_time < assistant.command_cooldown:
                        print(f"{Fore.LIGHTBLACK_EX}‚è≠Ô∏è  –ó–∞–Ω–∞–¥—Ç–æ —à–≤–∏–¥–∫–æ, —á–µ–∫–∞—é...\n")
                        continue
                    
                    # –û–±—Ä–æ–±–∏—Ç–∏ –∫–æ–º–∞–Ω–¥—É
                    assistant.last_command_time = current_time
                    assistant.process_command(command_text)
                    
                    print(f"\n{Fore.CYAN}üéß –ü—Ä–æ–¥–æ–≤–∂—É—é —Å–ª—É—Ö–∞—Ç–∏...\n")
            else:
                # –†–µ–∂–∏–º –±–µ–∑ –∞–∫—Ç–∏–≤–∞—Ü—ñ—ó (—è–∫ —Ä–∞–Ω—ñ—à–µ, –∞–ª–µ –∑ –≤—ñ–¥–ª—ñ–∫–æ–º)
                audio = record_audio_with_countdown(
                    LISTEN_DURATION,
                    SAMPLE_RATE,
                    "–°–ª—É—Ö–∞—é"
                )
                
                if not check_volume(audio):
                    continue
                
                text = transcribe_audio(audio, w2v_model, w2v_processor, device)
                
                if not text:
                    continue
                
                print(f"{Fore.LIGHTBLACK_EX}üîâ {text}")
                
                if should_ignore_command(text):
                    print(f"{Fore.LIGHTBLACK_EX}‚è≠Ô∏è  –Ü–≥–Ω–æ—Ä–æ–≤–∞–Ω–æ (—Ñ—ñ–ª—å—Ç—Ä)")
                    continue
                
                current_time = time.time()
                if current_time - assistant.last_command_time < assistant.command_cooldown:
                    print(f"{Fore.LIGHTBLACK_EX}‚è≠Ô∏è  –ó–∞–Ω–∞–¥—Ç–æ —à–≤–∏–¥–∫–æ, —á–µ–∫–∞—é...")
                    continue
                
                print(f"\n{Back.GREEN}{Fore.BLACK} ‚ú® –û–ë–†–û–ë–ö–ê –ö–û–ú–ê–ù–î–ò {Style.RESET_ALL}")
                print(f"{Fore.BLUE}üí¨ [–ö–æ–º–∞–Ω–¥–∞]: {Fore.WHITE}{text}")
                
                assistant.last_command_time = current_time
                assistant.process_command(text)
                
                print(f"\n{Fore.CYAN}üéß –ü—Ä–æ–¥–æ–≤–∂—É—é —Å–ª—É—Ö–∞—Ç–∏...\n")
            
        except KeyboardInterrupt:
            print(f"\n\n{Fore.YELLOW}üëã –í–∏–º–∏–∫–∞—é—Å—å...")
            assistant.is_listening = False
            break
        except Exception as e:
            print(f"{Fore.RED}‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
            time.sleep(0.5)

if __name__ == "__main__":
    main()
