import os
import sys

# –î–æ–¥–∞—Ç–∏ —à–ª—è—Ö–∏ –¥–æ CUDA –±—ñ–±–ª—ñ–æ—Ç–µ–∫
venv_path = sys.prefix
nvidia_paths = [
    os.path.join(venv_path, 'Lib', 'site-packages', 'nvidia', 'cublas', 'bin'),
    os.path.join(venv_path, 'Lib', 'site-packages', 'nvidia', 'cudnn', 'bin'),
    os.path.join(venv_path, 'Lib', 'site-packages', 'nvidia', 'cuda_runtime', 'bin'),
]

for path in nvidia_paths:
    if os.path.exists(path):
        os.environ['PATH'] = path + os.pathsep + os.environ['PATH']
        try:
            os.add_dll_directory(path)
        except:
            pass

import sounddevice as sd
import numpy as np
from faster_whisper import WhisperModel
import requests
import json

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
SAMPLE_RATE = 16000
DURATION = 3  # —Å–µ–∫—É–Ω–¥ –∑–∞–ø–∏—Å—É
LM_STUDIO_URL = "http://localhost:1234/v1/chat/completions"

def ask_llm(user_message):
    """–í—ñ–¥–ø—Ä–∞–≤–∏—Ç–∏ –∑–∞–ø–∏—Ç –¥–æ LM Studio"""
    try:
        response = requests.post(LM_STUDIO_URL, 
            json={
                "messages": [
                    {"role": "system", "content": "–¢–∏ –∫–æ—Ä–∏—Å–Ω–∏–π –∞—Å–∏—Å—Ç–µ–Ω—Ç. –í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é –∫–æ—Ä–æ—Ç–∫–æ —ñ –ø–æ —Å—É—Ç—ñ."},
                    {"role": "user", "content": user_message}
                ],
                "temperature": 0.2,
                "max_tokens": 512,
                "stream": False
            },
            timeout=60
        )
        
        if response.status_code == 200:
            return response.json()['choices'][0]['message']['content']
        else:
            return f"–ü–æ–º–∏–ª–∫–∞: {response.status_code}"
    except requests.exceptions.ConnectionError:
        return "‚ùå –ù–µ –º–æ–∂—É –∑'—î–¥–Ω–∞—Ç–∏—Å—è –∑ LM Studio. –ü–µ—Ä–µ–∫–æ–Ω–∞–π—Å—è, —â–æ —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω–∏–π!"
    except Exception as e:
        return f"‚ùå –ü–æ–º–∏–ª–∫–∞: {str(e)}"

print("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è Whisper –º–æ–¥–µ–ª—ñ...")
whisper_model = WhisperModel(
    "medium",
    device="cuda",
    compute_type="float16"
)

print("–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑'—î–¥–Ω–∞–Ω–Ω—è –∑ LM Studio...")
try:
    test_response = requests.get("http://localhost:1234/v1/models", timeout=1)
    if test_response.status_code == 200:
        models = test_response.json()
        print(f"‚úÖ LM Studio –ø—ñ–¥–∫–ª—é—á–µ–Ω–æ! –ú–æ–¥–µ–ª—å: {models['data'][0]['id']}")
    else:
        print("‚ö†Ô∏è  LM Studio –ø—Ä–∞—Ü—é—î, –∞–ª–µ —î –ø—Ä–æ–±–ª–µ–º–∏ –∑ API")
except:
    print("‚ùå LM Studio –Ω–µ –∑–∞–ø—É—â–µ–Ω–∏–π! –ó–∞–ø—É—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä –≤ LM Studio.")
    exit()

print("\n=== –ì–æ—Ç–æ–≤–æ! ===\n")

while True:
    print("–ù–∞—Ç–∏—Å–Ω–∏ Enter —â–æ–± –ø–æ—á–∞—Ç–∏ –∑–∞–ø–∏—Å (–∞–±–æ 'q' –¥–ª—è –≤–∏—Ö–æ–¥—É)...")
    user_input = input()
    
    if user_input.lower() == 'q':
        print("–í–∏—Ö—ñ–¥...")
        break
    
    print(f"üé§ –ì–æ–≤–æ—Ä–∏ ({DURATION} —Å–µ–∫—É–Ω–¥)...")
    
    # –ó–∞–ø–∏—Å –∞—É–¥—ñ–æ
    audio = sd.rec(
        int(DURATION * SAMPLE_RATE),
        samplerate=SAMPLE_RATE,
        channels=1,
        dtype=np.float32
    )
    sd.wait()
    
    audio = np.squeeze(audio)
    
    # –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –º–æ–≤–ª–µ–Ω–Ω—è
    print("üîç –†–æ–∑–ø—ñ–∑–Ω–∞—é...")
    segments, info = whisper_model.transcribe(
        audio,
        language="uk"
    )
    
    recognized_text = ""
    for seg in segments:
        recognized_text += seg.text
    
    if not recognized_text.strip():
        print("–ù—ñ—á–æ–≥–æ –Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ. –°–ø—Ä–æ–±—É–π —â–µ —Ä–∞–∑.\n")
        continue
    
    print(f"\nüí¨ [–¢–∏ —Å–∫–∞–∑–∞–≤]: {recognized_text}")
    
    # –í—ñ–¥–ø—Ä–∞–≤–∫–∞ –¥–æ LLM
    print("ü§î [LLM –¥—É–º–∞—î...]")
    
    answer = ask_llm(recognized_text)
    
    print(f"\nü§ñ [–í—ñ–¥–ø–æ–≤—ñ–¥—å]: {answer}\n")
    print("-" * 60 + "\n")